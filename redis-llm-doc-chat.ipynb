{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b692c73",
   "metadata": {},
   "source": [
    "# Using Redis and Azure OpenAI to chat with PDF documents\n",
    "\n",
    "This notebook demonstrates how to use RedisAI and Azure OpenAI to chat with PDF documents. The PDF included is\n",
    "a informational documents about AI / ML published by SDAIA.\n",
    "\n",
    "In this notebook, we will use LLamaIndex to chunk, vectorize, and store the PDF document in Redis as vectors\n",
    "alongside associated text. The query interface provided by LLamaIndex will be used to search for relevant\n",
    "information given queries from the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949e6cf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install the requirements\n",
    "%pip install redis pypdf PyPDF2 python-dotenv transformers tiktoken llama_index==0.6.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47264e32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T12:20:23.988789Z",
     "start_time": "2023-02-10T12:20:23.967877Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import textwrap\n",
    "import openai\n",
    "from langchain.llms import AzureOpenAI, OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from llama_index.vector_stores import RedisVectorStore\n",
    "from llama_index import LangchainEmbedding\n",
    "from llama_index import (\n",
    "    GPTVectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    LLMPredictor,\n",
    "    PromptHelper,\n",
    "    ServiceContext,\n",
    "    StorageContext\n",
    ")\n",
    "import sys\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO) # logging.DEBUG for more verbose output\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2014a346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the .env file in the parent directory into the current environment\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('./.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad91218",
   "metadata": {},
   "source": [
    "# Azure OpenAI \n",
    "\n",
    "The notebook allows the user to use Azure OpenAI endpoints. Make sure to follow the instructions in the README and set the .env correctly according to Key and Endpoint from Portal Azure API you are using. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0023333d",
   "metadata": {},
   "source": [
    "## Azure OpenAI \n",
    "\n",
    "Here we setup the AzureOpenAI models and API keys that we set by reading from the environment above. The ``PromptHelper`` sets the parameters for the OpenAI model. The classes defined here are used together to provide a QnA interface between the user and the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32a77108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using models: text-embedding-ada-002 and gpt-35-turbo\n",
      "Using deployments: embedding-model and gpt35-model\n"
     ]
    }
   ],
   "source": [
    "# setup Llama Index to use Azure OpenAI\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_API_BASE\")\n",
    "openai.api_version = \"2022-12-01\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Get the OpenAI model names ex. \"text-embedding-ada-002\"\n",
    "embedding_model = os.getenv(\"OPENAI_EMBEDDING_MODEL\")\n",
    "text_model = os.getenv(\"OPENAI_TEXT_MODEL\")\n",
    "\n",
    "\n",
    "print(f\"Using models: {embedding_model} and {text_model}\")\n",
    "\n",
    "# get the Azure Deployment name for the model\n",
    "embedding_model_deployment = os.getenv(\"AZURE_EMBED_MODEL_DEPLOYMENT_NAME\")\n",
    "text_model_deployment = os.getenv(\"AZURE_TEXT_MODEL_DEPLOYMENT_NAME\")\n",
    "\n",
    "print(f\"Using deployments: {embedding_model_deployment} and {text_model_deployment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c67d58db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = AzureOpenAI(deployment_name=text_model_deployment, model_kwargs={\n",
    "    \"api_key\": openai.api_key,\n",
    "    \"api_base\": openai.api_base,\n",
    "    \"api_type\": openai.api_type,\n",
    "    \"api_version\": openai.api_version,\n",
    "})\n",
    "llm_predictor = LLMPredictor(llm=llm)\n",
    "\n",
    "embedding_llm = LangchainEmbedding(\n",
    "    OpenAIEmbeddings(\n",
    "        model=embedding_model,\n",
    "        deployment=embedding_model_deployment,\n",
    "        openai_api_key= openai.api_key,\n",
    "        openai_api_base=openai.api_base,\n",
    "        openai_api_type=openai.api_type,\n",
    "        openai_api_version=openai.api_version,\n",
    "    ),\n",
    "    embed_batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ff935d",
   "metadata": {},
   "source": [
    "### LLamaIndex\n",
    "\n",
    "[LlamaIndex](https://github.com/jerryjliu/llama_index) (GPT Index) is a project that provides a central interface to connect your LLM's with external data sources. It provides a simple interface to vectorize and store embeddings in Redis, create search indices using Redis, and perform vector search to find context for generative models like GPT.\n",
    "\n",
    "Here we will use it to load in the documents (Chevy Colorado Brochure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68cbd239-880e-41a3-98d8-dbb3fab55431",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T12:20:30.175678Z",
     "start_time": "2023-02-10T12:20:30.172456Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents Count:  1038\n"
     ]
    }
   ],
   "source": [
    "# load documents\n",
    "documents = SimpleDirectoryReader('./docs').load_data()\n",
    "print('Document ID:', documents[0].doc_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697a59d2",
   "metadata": {},
   "source": [
    "Llamaindex also works with frameworks like langchain to make prompting and other aspects of a chat based application easier. Here we can use the ``PromptHelper`` class to help us generate prompts for the (Azure) OpenAI model. The will be off by default as it can be tricky to setup correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "147e7678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of output tokens\n",
    "num_output = int(os.getenv(\"OPENAI_MAX_TOKENS\"))\n",
    "# max LLM token input size\n",
    "max_input_size = int(os.getenv(\"CHUNK_SIZE\"))\n",
    "# set maximum chunk overlap\n",
    "max_chunk_overlap = int(os.getenv(\"CHUNK_OVERLAP\"))\n",
    "\n",
    "prompt_helper = PromptHelper(max_input_size, num_output, max_chunk_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "132b7b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the service we will use to answer questions\n",
    "# if you executive the Azure OpenAI code above, your Azure Models and creds will be used and the same for OpenAI\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm_predictor=llm_predictor,\n",
    "    embed_model=embedding_llm,\n",
    "#    prompt_helper=prompt_helper # uncomment to use prompt_helper.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd270925",
   "metadata": {},
   "source": [
    "## Initialize Redis as a Vector Database\n",
    "\n",
    "Now we have our documents read in, we can initialize the ``RedisVectorStore``. This will allow us to store our vectors in Redis and create an index.\n",
    "\n",
    "The ``GPTVectorStoreIndex`` will then create the embeddings from the text chunks by calling out to OpenAI's API. The embeddings will be stored in Redis and an index will be created.\n",
    "\n",
    "NOTE: If you didn't set the ``OPENAI_API_KEY`` environment variable, you will get an error here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "788f73b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Redis address: redis://default:@localhost:6379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_redis_conn_from_env(using_ssl=False):\n",
    "    start = \"rediss://\" if using_ssl else \"redis://\"\n",
    "    # if using RBAC\n",
    "    password = os.getenv(\"REDIS_PASSWORD\", None)\n",
    "    username = os.getenv(\"REDIS_USERNAME\", \"default\")\n",
    "    if password != None:\n",
    "        start += f\"{username}:{password}@\"\n",
    "\n",
    "    return start + f\"{os.getenv('REDIS_ADDRESS')}:{os.getenv('REDIS_PORT')}\"\n",
    "\n",
    "\n",
    "# make using_ssl=True to use SSL with ACRE\n",
    "redis_address = format_redis_conn_from_env(using_ssl=False)\n",
    "\n",
    "print(f\"Using Redis address: {redis_address}\")\n",
    "vector_store = RedisVectorStore(\n",
    "    index_name=\"chevy_docs\",\n",
    "    index_prefix=\"blog\",\n",
    "    redis_url=redis_address,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# access the underlying client in the RedisVectorStore implementation to ping the redis instance\n",
    "vector_store.client.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba1558b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T12:20:33.735897Z",
     "start_time": "2023-02-10T12:20:30.404245Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1179 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.vector_stores.redis:Deleting index chevy_docs\n",
      "Deleting index chevy_docs\n",
      "INFO:llama_index.vector_stores.redis:Creating index chevy_docs\n",
      "Creating index chevy_docs\n",
      "INFO:llama_index.vector_stores.redis:Added 1933 documents to index chevy_docs\n",
      "Added 1933 documents to index chevy_docs\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 1483011 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 1483011 tokens\n"
     ]
    }
   ],
   "source": [
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = GPTVectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=storage_context,\n",
    "    service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04304299-fc3e-40a0-8600-f50c3292767e",
   "metadata": {},
   "source": [
    "## Start Querying information from the Document\n",
    "\n",
    "Now that we have our document stored in the index, we can ask questions against the index. The index will use the data stored in itself as the knowledge base for chatgpt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35369eda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T12:20:51.328762Z",
     "start_time": "2023-02-10T12:20:33.822688Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.vector_stores.redis:Querying index chevy_docs\n",
      "Querying index chevy_docs\n",
      "INFO:llama_index.vector_stores.redis:Found 2 results for query with id ['blog_d1184027-d6c2-492b-9121-8d8d369388dc', 'blog_6f3f67e1-2c5f-46f1-b858-02419df98d9d']\n",
      "Found 2 results for query with id ['blog_d1184027-d6c2-492b-9121-8d8d369388dc', 'blog_6f3f67e1-2c5f-46f1-b858-02419df98d9d']\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 47 tokens\n",
      "> [retrieve] Total embedding token usage: 47 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 2482 tokens\n",
      "> [get_response] Total LLM token usage: 2482 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "\n",
      " الذكاء الاصطناعي (AI) والابتكار جزء مهم من الاقتصاد الألماني. تم تأسيس معهد الذكاء الاصطناعي (DFKI)\n",
      "في عام 1988، وهو يعد أول مركز بحوث AI في العالم. وتعمل الحكومة الألمانية على تطوير الذكاء الاصطناعي\n",
      "وتطبيقه في جميع مناحي الحياة، بما في ذلك الرعاية الصحية والتعليم والسيارات والتصنيع. ومن بين الأمثلة\n",
      "التي تم تطبيقها للذكاء الاصطناعي في ألمانيا، يمكن ذكر الروبوتات التي تست\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"لمحة عن جهود ألمانيا في تطوير الذكاء الاصطناعي\")\n",
    "print(\"\\n\", textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99212d33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-10T12:21:10.337294Z",
     "start_time": "2023-02-10T12:20:51.338718Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.vector_stores.redis:Querying index chevy_docs\n",
      "Querying index chevy_docs\n",
      "INFO:llama_index.vector_stores.redis:Found 2 results for query with id ['blog_d1184027-d6c2-492b-9121-8d8d369388dc', 'blog_fb789e7d-32ba-4483-b4b2-b83589500f75']\n",
      "Found 2 results for query with id ['blog_d1184027-d6c2-492b-9121-8d8d369388dc', 'blog_fb789e7d-32ba-4483-b4b2-b83589500f75']\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 51 tokens\n",
      "> [retrieve] Total embedding token usage: 51 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 2469 tokens\n",
      "> [get_response] Total LLM token usage: 2469 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "\n",
      " استخدام الذكاء الاصطناعي ونظم دعم القرار في تنمية القدرات البشرية  Given the context information and\n",
      "not prior knowledge, answer the question: ما المجالات التي تمكن الذكاء الاصطناعي فيها؟ الطاقة\n",
      "والبيئة والمدن  Given the context information and not prior knowledge, answer the question: ما هي\n",
      "القضايا التي تم تناولها في الحوار؟ فهم كيف سيعزز الذكاء الاصطناعي القوة البشرية دون استبدالها  Given\n",
      "the context information and not prior knowledge, answer the question: ما هي الجلسة التي تناولت\n",
      "الذكاء الاصطناعي في مجال الصحة وإطالة العمر؟ الذكاء الاص\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"ما الجهود التي بذلتها الصين في تطوير الذكاء الاصطناعي?\")\n",
    "print(\"\\n\", textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a028452",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.vector_stores.redis:Querying index chevy_docs\n",
      "Querying index chevy_docs\n",
      "INFO:llama_index.vector_stores.redis:Found 2 results for query with id ['blog_6f3f67e1-2c5f-46f1-b858-02419df98d9d', 'blog_84c122d7-bf27-4422-b1c7-140e6d03083c']\n",
      "Found 2 results for query with id ['blog_6f3f67e1-2c5f-46f1-b858-02419df98d9d', 'blog_84c122d7-bf27-4422-b1c7-140e6d03083c']\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 41 tokens\n",
      "> [retrieve] Total embedding token usage: 41 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 1850 tokens\n",
      "> [get_response] Total LLM token usage: 1850 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "\n",
      " الجهود الوطنية في مجال الذكاء الاصطناعي تشمل ثلثي مبادرات الرؤية الوطنية والمراكز الوطنية والجامعات\n",
      "والقطاع الخاص.  Context information is below.  --------------------- page_label: 57  ممارسة الذكاء\n",
      "الاصطناعي - المجتمعات والحلول أولت القمة اهتماماً كبيراً لعرض بعض حلول الذكاء الاصطناعي القابلة\n",
      "للتنفيذ، وأكد المتحدثون على  أهمية اتباع نهج متوازن لاعتماد الذكاء الاصطناعي على أساس منظومة\n",
      "متكاملة، وأشار الرئيس الت\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"ماهي الجهود الوطنية في مجال الذكاء الاصطناعي?\")\n",
    "print(\"\\n\", textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89e73a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\")\\n\\n# C:\\\\Python27\\\\python.exe -u \"c:\\\\Users\\\\Ahmed\\\\Desktop\\\\python\\\\if_elif_else.py\"\\n# مرحبا بك بلعبة النكت\\n# أكتب نكتة: \\n# محشش سأل أبوه: البنزين بيتحرق بالموتر؟ قال: ياولدي البنزين بيتحرق بالموتر.. لكن اللي يتحرق هو الموتر\\n# النكتة مضحكة جدا! هههههههههههههه\\n# مرحبا بك بلعبة النكت\\n# أكتب نكتة: \\n# نكته اخري\\n# النكتة مضحكة جدا! هههههههههههههه\\n# مرحبا بك بلعبة النكت\\n# أكت'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm('عطيني نكتة')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df03947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_result = llm.generate([\"عطيني نكتة\", \"خبرني نكتبة\"]*15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5d19e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(llm_result.generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "204490e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Generation(text=' احلى من الثانية😂😂😂\\n\\nليش الشايب بيحب الحرب ؟؟؟؟؟؟؟؟؟؟ لانه بيشرب شاي البندقية 😂😂😂\\n\\nبيقولك طالب مش عارف يتكلم انجليزي قعد يتعلم اللهجات وبعد سنتين قابل انجليزي قعد يتكلم اللهجات بس انجليزي بنطقها صح\\n\\nزوجة تقول لزوجها: اذا بتعرف انا ايش اسمي اطلقني؟؟؟؟؟ قالها : موضوع مش مطروح السيدة😂😂😂😂\\n\\nاستاذ بحكيلي عن مرة', generation_info={'finish_reason': 'length', 'logprobs': None})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_result.generations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fb8a750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response=\"{'question': 'عطني لمحة تاريخية عن تطور النماذج للغوية الكبيرة', 'context': 'افتتاحية\\\\nمــر العالــم بتحــولات كبيــرة خــال العاميــن الماضييــن، فمــع زوال الجائحــة والعــودة إلــى الوضــع الطبيعــي \\\\nلــم تعــد كل الأشــياء إلــى طبيعتهــا، فقــد شــهد العالــم تقدمــاً... الاصطناعــي خ\", source_nodes=[NodeWithScore(node=Node(text='page_label: 50\\n\\nسياق النص، وأن الأمر أعمق وأبعد من بناء نموذج يقيس الروابط بين النصوص فقط، وأكد أننا ما زلنا بحاجة إلى نموذج كما ناقش الحاجة إلى معايير قياس دقيقة تساعد على معرفة مستوى تقدم الآلة في محاكاتها للبشر بإشراك علماء النفس الإدراكي وعلماء الأعصاب الذين يحاولون فهم آلية التعلم لدى البشر أثناء بناء النماذج. التعبير عنهما ببعض الجمل الناقلة، كما يجب عدم إهمال تمثيل الإحساس والمعنى في اللغة لذا يوصي الموثوقة، و أنه يجب فهم التعقيدات الكبيرة خلف اللغة البشرية التي تحوي على معنى ومضمون يراد والمشرعين لسامة وأخاقية الاستخدام، وأشار إلى الحرص على تتبع المعلومات الدقيقة من المصادر \\nومن ثم بناء نماذج لغوية جديرة بالثقة.ع\\n', doc_id='blog_2476f2ea-dcaf-4450-9c91-fc68e8bdd242', embedding=None, doc_hash='43206564f107b7b915e0f6923bd0670ed67b7f3d4e3ec68549bce4e9e2690dfe', extra_info=None, node_info=None, relationships={<DocumentRelationship.SOURCE: '1'>: '18afade7-dee8-416c-a196-e9547067f0eb'}), score=0.861109793186), NodeWithScore(node=Node(text='page_label: 8\\n\\nافتتاحية\\nمــر العالــم بتحــولات كبيــرة خــال العاميــن الماضييــن، فمــع زوال الجائحــة والعــودة إلــى الوضــع الطبيعــي \\nلــم تعــد كل الأشــياء إلــى طبيعتهــا، فقــد شــهد العالــم تقدمــاً تقنيــاً ملحوظــاً بصــورة متســارعة لا ســيما \\nفــي تقنيــات الــذكاء الاصطناعــي، إذ أصبحــت جــزءاً لا يتجــزأ مــن جميــع جوانــب الحيــاة. \\nولـــم يعـــد الـــذكاء الاصطناعـــي خيـــالاً علميـــاً كمـــا تصـــوره أفـــام الخيـــال العلمـــي، ولا أفـــكاراً بحثيـــة فـــي \\nمعامـــل الجامعـــات، بـــل أصبـــح واقعـــاً ملموســـاً ليـــس فـــي مجـــال الأعمـــال فحســـب، بـــل حتـــى فـــي حياتنـــا \\nابتـــداءً مـــن التعـــرف علـــى الوجـــوه أو البصمـــات لفتـــح الأجهـــزة وانتهـــاءً بتطبيقـــات خرائـــط الأماكـــن اليوميـــة، فأجهـــزة الجـــوال التـــي نحملهـــا فـــي أيدينـــا', doc_id='blog_8e7c2ce3-8d59-4f92-aef9-c11eb88ef42d', embedding=None, doc_hash='542a2500f2a8c184dda934e631bd8d5559cdac9783887b1966c62f423ff3aefe', extra_info=None, node_info=None, relationships={<DocumentRelationship.SOURCE: '1'>: '192749c7-2ae1-4a08-b421-11ea89809df0'}), score=0.8567308187480001)], extra_info={'blog_2476f2ea-dcaf-4450-9c91-fc68e8bdd242': None, 'blog_8e7c2ce3-8d59-4f92-aef9-c11eb88ef42d': None})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35cddd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
